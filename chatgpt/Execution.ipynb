{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall flow of adding a 'bot' for a recording \n",
    "# steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1 \n",
    "- get the raw data \n",
    "    - video file - video dir\n",
    "    - audio file - audio dir\n",
    "    - youtube link \n",
    "        - audio file - youtube dir\n",
    "step 2\n",
    "- process audio files to a compressed standard ogg format - processed dir \n",
    "- chop into chunks - chopped dir (tmp)\n",
    "- whisper for transcribing each chunk, build a single json file for the audio - transcript dir\n",
    "- summarise the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 - VIDEO FILE \n",
    "from chatgpt.video_to_audio import extract_audio\n",
    "from dirs import *\n",
    "\n",
    "video_filename = \"Juan_Camilo_Avendano_and_Ankit_Gupta.mp4\"\n",
    "\n",
    "        \n",
    "audio_file_path = extract_audio(video_filepath=Path(VIDEO_DIR,video_filename).__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2 --\n",
    "file = \"Juan_Camilo_Avendano_and_Ankit_Gupta.mp3\"\n",
    "base_prmpt = \"INTERVIEW CALL BETWEEN TWO PEOPLE:\" + file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from concall_audio_to_text import create_text_from_audio\n",
    "## ---- USES WHISPER CREDIT ------ ###  \n",
    "\n",
    "output_file = create_text_from_audio(file_name=file,base_prompt=base_prmpt,youtube=False)\n",
    "    \n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - summarise as per use case - optional but also not.\n",
    "# -- uses openai -- #\n",
    "from chatgpt.concall_text_to_kowledge import create_text_meta_doc\n",
    "\n",
    "summary_prmpt_interview = \"You are a helpful assistant to aid a USER INTERVIEW CALL. The transcript of the call will be provided in chunks \\\n",
    "                         Provide the summary highlihgting the sentiments and possible pain points of the user.  \\\n",
    "                            Remember that the Interviewr is A PRODUCT MANAGER and the other person is a CHURNED OUT USER OF THE APP SCISPACE\"\n",
    "sections_interview = ['INTRO','QA','DISCUSSION','TAKEAWAYS']\n",
    "\n",
    "\n",
    "summary_file = create_text_meta_doc(ts_filename=file,chunk_size=1000,summariser_prompt=summary_prmpt_interview,sections=sections_interview)\n",
    "summary_file\n",
    "    # print(test_load_ts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding k 0\n",
      "embedding k 1\n",
      "embedding k 2\n",
      "embedding k 3\n",
      "embedding k 4\n",
      "embedding k 5\n",
      "embedding k 6\n",
      "embedding k 7\n",
      "embedding k 8\n",
      "embedding k 9\n",
      "embedding k 10\n",
      "embedding k 11\n",
      "embedding k 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/anubhavtomar/2023_projects/chatgpt/chatgpt/data/processed/transcripts/summary/embeddings/Juan_Camilo_Avendano_and_Ankit_Gupta.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 \n",
    "from concall_text_to_kowledge import create_embeddings_from_chunk_doc\n",
    "\n",
    "\n",
    "embedding_doc_file = create_embeddings_from_chunk_doc(filename=file)\n",
    "embedding_doc_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specific\n",
      "1787\n",
      "record saved  True\n",
      "ANSWER:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The pain points mentioned by the user include:\\n1. Support taking too much time, leading to delays in their work.\\n2. Inaccurate or irrelevant information provided by the system, especially in the summarize abstract feature.\\n3. Difficulty in using Copilot, with it not generating responses effectively.\\n4. Loss of trust in the system due to persistent issues and lack of improvement despite assurances.\\n5. Limited trial period with poor results leading to a loss of trust in the premium subscription.\\n6. Preference for using alternative methods like GPT for better results compared to the platform.\\n7. Dissatisfaction with the lack of functionality and useful outputs from the system, leading to doubts about the value of the subscription.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5 - final step\n",
    " \n",
    "from concall_question_over_knowledge import answer_question, get_context_corpus\n",
    "\n",
    "\n",
    "filename =  'Juan_Camilo_Avendano_and_Ankit_Gupta.json'\n",
    "question_prompt = f\" You will be provided with transcript chunks of an interview call between a Product manger and a customer \\\n",
    "                            the user is a churned out user and the PM seeks to gains some insights into the reasons.\"\n",
    "def test_answer_from_gpt_scispace( question_prompt=question_prompt):\n",
    "    doc = get_context_corpus(file_name=filename,)\n",
    "    \n",
    "    # question = \"what is this call about?\"\n",
    "    question = \"what are the pain points mentioned by the user ?\"\n",
    "    # question = \"what are the action items i can add in my next quarter's roadmap for the copilot based on the users response?\"\n",
    "\n",
    "    \n",
    "    \n",
    "    return  answer_question(doc,question,\n",
    "                            file_name=filename,\n",
    "                            question_prompt=question_prompt,\n",
    "                            _top_n=5)\n",
    "test_answer_from_gpt_scispace()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
