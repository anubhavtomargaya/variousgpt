{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall flow of adding a 'bot' for a recording \n",
    "# steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- get the raw data \n",
    "    - video file - video dir\n",
    "    - audio file - audio dir\n",
    "    - youtube link \n",
    "        - audio file - youtube dir\n",
    "\n",
    "- process audio files to a compressed standard ogg format - processed dir \n",
    "- chop into chunks - chopped dir (tmp)\n",
    "- whisper for transcribing each chunk, build a single json file for the audio - transcript dir\n",
    "- summarise the chunks into json with sections \n",
    "- embed\n",
    "- ask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 - VIDEO FILE \n",
    "from video_to_audio import extract_audio\n",
    "from dirs import *\n",
    "\n",
    "video_filename = \"Juan_Camilo_Avendano_and_Ankit_Gupta.mp4\"\n",
    "audio_file_path = extract_audio(video_filepath=Path(VIDEO_DIR,video_filename).__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2 -- VIDEO FILE to TEXT\n",
    "file = \"Juan_Camilo_Avendano_and_Ankit_Gupta.mp3\"\n",
    "base_prmpt = \"INTERVIEW CALL BETWEEN TWO PEOPLE:\" + file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---- USES WHISPER CREDIT ------ ###  \n",
    "from concall_audio_to_text import create_text_from_audio\n",
    "\n",
    "output_file = create_text_from_audio(file_name=file,base_prompt=base_prmpt,youtube=False)\n",
    "    \n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - summarise as per use case - optional but also not.\n",
    "# -- uses openai -- #\n",
    "\n",
    "from chatgpt.concall_text_to_kowledge import create_text_meta_doc\n",
    "\n",
    "summary_prmpt_interview = \"You are a helpful assistant to aid a USER INTERVIEW CALL. The transcript of the call will be provided in chunks \\\n",
    "                         Provide the summary highlihgting the sentiments and possible pain points of the user.  \\\n",
    "                            Remember that the Interviewr is A PRODUCT MANAGER and the other person is a CHURNED OUT USER OF THE APP SCISPACE\"\n",
    "sections_interview = ['INTRO','QA','DISCUSSION','TAKEAWAYS']\n",
    "\n",
    "\n",
    "summary_file = create_text_meta_doc(ts_filename=file,chunk_size=1000,summariser_prompt=summary_prmpt_interview,sections=sections_interview)\n",
    "summary_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding k 0\n",
      "embedding k 1\n",
      "embedding k 2\n",
      "embedding k 3\n",
      "embedding k 4\n",
      "embedding k 5\n",
      "embedding k 6\n",
      "embedding k 7\n",
      "embedding k 8\n",
      "embedding k 9\n",
      "embedding k 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/anubhavtomar/2023_projects/chatgpt/chatgpt/data/processed/transcripts/summary/embeddings/Delhivery_Ltd_Q4_FY2023-24_Earnings_Conference_Call.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 \n",
    "from concall_text_to_kowledge import create_embeddings_from_chunk_doc\n",
    "\n",
    "\n",
    "embedding_doc_file = create_embeddings_from_chunk_doc(filename=file)\n",
    "embedding_doc_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the above cells\n",
    "### NOW ASK QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specific\n",
      "1812\n",
      "record saved  True\n",
      "ANSWER:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To help users like the one in the transcript who faced challenges with using the platform and ultimately churned out, you can take the following steps:\\n\\n1. **Feedback Collection**: It's important to actively collect feedback from users who have churned out to understand their pain points and reasons for leaving. This can be done through surveys, feedback forms, or even direct interviews like the one in the transcript.\\n\\n2. **Identifying Patterns**: Look for common themes or patterns in the feedback received from churned users. In this case, the user faced issues with getting relevant information from the platform, slow customer support, and lack of trust in the system's functionality.\\n\\n3. **Improving Platform Functionality**: Address the specific issues highlighted by the user,\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5 - final step\n",
    " \n",
    "from concall_question_over_knowledge import answer_question, get_context_corpus\n",
    "\n",
    "organisation = 'Scispace - CoPilot'\n",
    "filename =  'Juan_Camilo_Avendano_and_Ankit_Gupta.json'\n",
    "question_prompt = f\" You will be provided with transcript chunks of an interview call between a Product manger and a customer \\\n",
    "                            the user is a churned out user and the PM seeks to gains some insights into the reasons. \\n  ORGANISATION : {organisation} \\n FILENAME : {filename}\"\n",
    "def test_answer_from_gpt_scispace( question_prompt=question_prompt):\n",
    "    doc = get_context_corpus(file_name=filename,)\n",
    "    \n",
    "    # question = \"what is this call about?\"\n",
    "    # question = \"what are the pain points mentioned by the user ?\"\n",
    "    # question = \"what are the action items i can add in my next quarter's roadmap for the copilot based on the users response?\"\n",
    "    question = \"How can I help this user or other users like him? How can I identify users like him?\"\n",
    "    \n",
    "    \n",
    "    return  answer_question(doc,question,\n",
    "                            file_name=filename,\n",
    "                            question_prompt=question_prompt,\n",
    "                            _top_n=5)\n",
    "test_answer_from_gpt_scispace()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
